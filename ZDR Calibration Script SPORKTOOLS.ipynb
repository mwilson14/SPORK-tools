{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\pyart\\graph\\cm.py:104: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'red' in spec:\n",
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\pyart\\graph\\cm_colorblind.py:32: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'red' in spec:\n",
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\botocore\\vendored\\requests\\packages\\urllib3\\_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n",
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\botocore\\vendored\\requests\\packages\\urllib3\\_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n"
     ]
    }
   ],
   "source": [
    "### This script will automatically detect ZDR arcs (and KDP feet) in WSR-88D radar data\n",
    "import matplotlib.pyplot as plt\n",
    "import pyart\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from metpy.units import atleast_1d, check_units, concatenate, units\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "from siphon.radarserver import RadarServer\n",
    "#rs = RadarServer('http://thredds-aws.unidata.ucar.edu/thredds/radarServer/nexrad/level2/S3/')\n",
    "#rs = RadarServer('http://thredds.ucar.edu/thredds/radarServer/nexrad/level2/IDD/')\n",
    "from datetime import datetime, timedelta\n",
    "from siphon.cdmr import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from metpy.units import atleast_1d, check_units, concatenate, units\n",
    "from shapely.geometry import polygon as sp\n",
    "import pyproj \n",
    "import shapely.ops as ops\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from functools import partial\n",
    "from shapely import geometry\n",
    "import netCDF4\n",
    "from scipy import ndimage as ndi\n",
    "#from skimage.feature import peak_local_max\n",
    "#from skimage import data, img_as_float\n",
    "from pyproj import Geod\n",
    "from metpy.calc import get_wind_dir, get_wind_speed, get_wind_components\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import pickle\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "import nexradaws\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year of start time\n",
    "yearstm = np.asarray([2013, 2013, 2012, 2012, 2013, 2012])\n",
    "#Month of case start time\n",
    "monthstm = np.asarray([5, 4, 2, 3, 1, 5])\n",
    "#Day of case start time\n",
    "daystm = np.asarray([20, 18, 29, 2, 29, 30])\n",
    "#Hour of case start time (in UTC)\n",
    "hourstm = np.asarray([20, 0, 0, 23, 21, 23])\n",
    "#Minute of case start time\n",
    "start_minstm = np.asarray([0, 0, 30, 0, 0, 0])\n",
    "#Duration of analysis period, in hours\n",
    "durationstm = np.asarray([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "#WSR-88D radar site\n",
    "stationstm = ['KTLX', 'KFDR', 'KICT', 'KOHX', 'KSRX', 'KSJT']\n",
    "#0C height + 1.5km\n",
    "h_calstm = [5100, 5400, 4325, 4400, 4700, 5425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual code for the ZDR calibration algorithm (more operational-ish version)\n",
    "def multi_case_algorithm_ML1(year, month, day, hour, start_min, duration, station, h_cal):    \n",
    "    #Settings\n",
    "    #Here, set the initial time of the archived radar loop you want.\n",
    "    #Changing this to pull in 15 minutes starting at the middle of the analysis period\n",
    "    dt3 = datetime(year,month, day, hour, start_min) # Our specified time\n",
    "    station = station\n",
    "    dt = dt3 + timedelta(hours=duration/2.0)\n",
    "    end_dt = dt + timedelta(hours=0.25)\n",
    "    #Set up nexrad interface\n",
    "    conn = nexradaws.NexradAwsInterface()\n",
    "    scans = conn.get_avail_scans_in_range(dt,end_dt,station)\n",
    "    #Change this to whatever folder you want the radar data to download into.\n",
    "    results = conn.download(scans, 'ZDRCAL/'+str(year)+str(month)+str(day)+str(hour)+station)\n",
    "    #Create times for possible file deletion later\n",
    "    year1=year\n",
    "    month1=month\n",
    "    day1=day\n",
    "    hour1=hour\n",
    "    #query = rs.query()\n",
    "    #Set the duration of the loop in hours\n",
    "    #query.stations(station).time_range(dt, dt + timedelta(hours=duration))\n",
    "    #cat = rs.get_catalog(query)\n",
    "    #cat.datasets\n",
    "    \n",
    "    #Create an option for just reading all files in a folder\n",
    "    #folder = 'Machine_Learning/LocalRadar/'+LocalFolder\n",
    "    \n",
    "    #Setting counters for figures and Pandas indices\n",
    "    f = 27\n",
    "    n = 1\n",
    "    storm_index = 0\n",
    "    scan_index = 0\n",
    "    #Get calibration height\n",
    "    h_oc = h_cal\n",
    "    #Make lists for the calibrations\n",
    "    zdr_cals = []\n",
    "    zdr_raw = []\n",
    "    #Create geod object for later distance and area calculations\n",
    "    g = Geod(ellps='sphere')\n",
    "    ####\n",
    "    #Actual algorithm code starts here\n",
    "    #for item in sorted(cat.datasets.items()):\n",
    "    for i,scan in enumerate(results.iter_success(),start=1):\n",
    "    #Local file option:\n",
    "    #for radar_file in os.listdir(folder):\n",
    "        #print(radar_file)\n",
    "        #Loop over all files in the dataset and pull out each 0.5 degree tilt for analysi\n",
    "        #ds = item[1]\n",
    "        try:\n",
    "            radar = scan.open_pyart()\n",
    "        except:\n",
    "            continue\n",
    "        #Local file option\n",
    "        #radar1 = pyart.io.nexrad_archive.read_nexrad_archive(folder+'/'+radar_file)\n",
    "        #print('file read')\n",
    "        time_start = netCDF4.num2date(radar.time['data'][0], radar.time['units'])\n",
    "        object_number=0.0\n",
    "        print(time_start)\n",
    "        month = time_start.month\n",
    "        if month < 10:\n",
    "            month = '0'+str(month)\n",
    "        hour = time_start.hour\n",
    "        if hour < 10:\n",
    "            hour = '0'+str(hour)\n",
    "        minute = time_start.minute\n",
    "        if minute < 10:\n",
    "            minute = '0'+str(minute)\n",
    "        day = time_start.day\n",
    "        if day < 10:\n",
    "            day = '0'+str(day)\n",
    "        time_beg = time_start - timedelta(minutes=0.5)\n",
    "        time_end = time_start + timedelta(minutes=0.5)\n",
    "        sec_beg = time_beg.second\n",
    "        sec_end = time_end.second\n",
    "        min_beg = time_beg.minute\n",
    "        min_end = time_end.minute\n",
    "        h_beg = time_beg.hour\n",
    "        h_end = time_end.hour\n",
    "        d_beg = time_beg.day\n",
    "        d_end = time_end.day\n",
    "        if sec_beg < 10:\n",
    "            sec_beg = '0'+str(sec_beg)\n",
    "        if sec_end < 10:\n",
    "            sec_end = '0'+str(sec_end)\n",
    "        if min_beg < 10:\n",
    "            min_beg = '0'+str(min_beg)\n",
    "        if min_end < 10:\n",
    "            min_end = '0'+str(min_end)\n",
    "        if h_beg < 10:\n",
    "            h_beg = '0'+str(h_beg)\n",
    "        if h_end < 10:\n",
    "            h_end = '0'+str(h_end)\n",
    "        if d_beg < 10:\n",
    "            d_beg = '0'+str(d_beg)\n",
    "        if d_end < 10:\n",
    "            d_end = '0'+str(d_end)\n",
    "        print(datetime.utcnow())\n",
    "        # mask out last 10 gates of each ray, this removes the \"ring\" around the radar.\n",
    "        #Bring in all of the ungridded fields\n",
    "        radar.fields['differential_reflectivity']['data'][:, -10:] = np.ma.masked\n",
    "        cc_ungridded = radar.fields['cross_correlation_ratio']['data']\n",
    "        ref_ungridded = radar.fields['reflectivity']['data']\n",
    "        zdr_ungridded = radar.fields['differential_reflectivity']['data']\n",
    "        print(zdr_ungridded.shape)\n",
    "        #Get ungridded gate altitudes\n",
    "        gate_altitude = radar.gate_altitude['data'][:]\n",
    "        #Convert to height ARL\n",
    "        h_agl = gate_altitude-radar.altitude['data'][0]\n",
    "        #Convert to height relative to calibration level\n",
    "        h_aoc = h_agl - h_oc\n",
    "\n",
    "        #Now start masking out ZDR data\n",
    "        zdr_c = np.copy(zdr_ungridded)\n",
    "        zdr_c = ma.masked_where(ref_ungridded < 20, zdr_c)\n",
    "        zdr_c = ma.masked_where(ref_ungridded > 35, zdr_c)\n",
    "        zdr_c = ma.masked_where(cc_ungridded < 0.99, zdr_c)\n",
    "        zdr_c = ma.masked_where(h_agl > (h_oc + 250), zdr_c)\n",
    "        zdr_c = ma.masked_where(h_agl < (h_oc - 250), zdr_c)\n",
    "        print(ma.MaskedArray.count(zdr_c))\n",
    "        #Testing for elevation stuff\n",
    "        alt_c = np.copy(h_agl)\n",
    "        alt_c = ma.masked_where(ref_ungridded < 20, alt_c)\n",
    "        alt_c = ma.masked_where(ref_ungridded > 35, alt_c)\n",
    "        alt_c = ma.masked_where(cc_ungridded < 0.99, alt_c)\n",
    "        alt_c = ma.masked_where(h_agl > (h_oc + 250), alt_c)\n",
    "        alt_c = ma.masked_where(h_agl < (h_oc - 250), alt_c)\n",
    "\n",
    "        #Get ungridded lats and lons\n",
    "        ungrid_lons = radar.gate_longitude['data']\n",
    "        ungrid_lats = radar.gate_latitude['data']\n",
    "        cenlat = radar.latitude['data'][0]\n",
    "        cenlon = radar.longitude['data'][0]\n",
    "        \n",
    "        #Get calibrations and raw means\n",
    "        zdr_m = np.nanmean(zdr_c)\n",
    "        zdr_ca = zdr_m - 0.2\n",
    "        zdr_cals.append(zdr_ca)\n",
    "        zdr_raw.append(zdr_m)\n",
    "            \n",
    "    return zdr_cals, zdr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual code for the ZDR calibration algorithm (Local folder option)\n",
    "def multi_case_algorithm_ML1_loc(year, month, day, hour, start_min, duration, station, h_cal, localfolder):    \n",
    "    #Settings\n",
    "    #Here, set the initial time of the archived radar loop you want.\n",
    "    #Changing this to pull in 15 minutes starting at the middle of the analysis period\n",
    "    dt3 = datetime(year,month, day, hour, start_min) # Our specified time\n",
    "    station = station\n",
    "    #dt = dt3 + timedelta(hours=duration/2.0)\n",
    "    #end_dt = dt + timedelta(hours=0.25)\n",
    "    #Set up nexrad interface\n",
    "    #conn = nexradaws.NexradAwsInterface()\n",
    "    #scans = conn.get_avail_scans_in_range(dt,end_dt,station)\n",
    "    #Change this to whatever folder you want the radar data to download into.\n",
    "    #results = conn.download(scans, 'ZDRCAL/'+str(year)+str(month)+str(day)+str(hour)+station)\n",
    "    #Create times for possible file deletion later\n",
    "    year1=year\n",
    "    month1=month\n",
    "    day1=day\n",
    "    hour1=hour\n",
    "    #query = rs.query()\n",
    "    #Set the duration of the loop in hours\n",
    "    #query.stations(station).time_range(dt, dt + timedelta(hours=duration))\n",
    "    #cat = rs.get_catalog(query)\n",
    "    #cat.datasets\n",
    "    LocalFolder=localfolder\n",
    "    #Create an option for just reading all files in a folder\n",
    "    folder = 'Machine_Learning/LocalRadar/'+LocalFolder\n",
    "    \n",
    "    #Setting counters for figures and Pandas indices\n",
    "    f = 27\n",
    "    n = 1\n",
    "    storm_index = 0\n",
    "    scan_index = 0\n",
    "    #Get calibration height\n",
    "    h_oc = h_cal\n",
    "    #Make lists for the calibrations\n",
    "    zdr_cals = []\n",
    "    zdr_raw = []\n",
    "    #Create geod object for later distance and area calculations\n",
    "    g = Geod(ellps='sphere')\n",
    "    ####\n",
    "    #Actual algorithm code starts here\n",
    "    #for item in sorted(cat.datasets.items()):\n",
    "    #for i,scan in enumerate(results.iter_success(),start=1):\n",
    "    #Local file option:\n",
    "    for radar_file in os.listdir(folder):\n",
    "        #print(radar_file)\n",
    "        #Loop over all files in the dataset and pull out each 0.5 degree tilt for analysi\n",
    "        #ds = item[1]\n",
    "        #radar = scan.open_pyart()\n",
    "        #Local file option\n",
    "        radar = pyart.io.nexrad_archive.read_nexrad_archive(folder+'/'+radar_file)\n",
    "        #print('file read')\n",
    "        time_start = netCDF4.num2date(radar.time['data'][0], radar.time['units'])\n",
    "        object_number=0.0\n",
    "        print(time_start)\n",
    "        month = time_start.month\n",
    "        if month < 10:\n",
    "            month = '0'+str(month)\n",
    "        hour = time_start.hour\n",
    "        if hour < 10:\n",
    "            hour = '0'+str(hour)\n",
    "        minute = time_start.minute\n",
    "        if minute < 10:\n",
    "            minute = '0'+str(minute)\n",
    "        day = time_start.day\n",
    "        if day < 10:\n",
    "            day = '0'+str(day)\n",
    "        time_beg = time_start - timedelta(minutes=0.5)\n",
    "        time_end = time_start + timedelta(minutes=0.5)\n",
    "        sec_beg = time_beg.second\n",
    "        sec_end = time_end.second\n",
    "        min_beg = time_beg.minute\n",
    "        min_end = time_end.minute\n",
    "        h_beg = time_beg.hour\n",
    "        h_end = time_end.hour\n",
    "        d_beg = time_beg.day\n",
    "        d_end = time_end.day\n",
    "        if sec_beg < 10:\n",
    "            sec_beg = '0'+str(sec_beg)\n",
    "        if sec_end < 10:\n",
    "            sec_end = '0'+str(sec_end)\n",
    "        if min_beg < 10:\n",
    "            min_beg = '0'+str(min_beg)\n",
    "        if min_end < 10:\n",
    "            min_end = '0'+str(min_end)\n",
    "        if h_beg < 10:\n",
    "            h_beg = '0'+str(h_beg)\n",
    "        if h_end < 10:\n",
    "            h_end = '0'+str(h_end)\n",
    "        if d_beg < 10:\n",
    "            d_beg = '0'+str(d_beg)\n",
    "        if d_end < 10:\n",
    "            d_end = '0'+str(d_end)\n",
    "        print(datetime.utcnow())\n",
    "        # mask out last 10 gates of each ray, this removes the \"ring\" around the radar.\n",
    "        #Bring in all of the ungridded fields\n",
    "        radar.fields['differential_reflectivity']['data'][:, -10:] = np.ma.masked\n",
    "        cc_ungridded = radar.fields['cross_correlation_ratio']['data']\n",
    "        ref_ungridded = radar.fields['reflectivity']['data']\n",
    "        zdr_ungridded = radar.fields['differential_reflectivity']['data']\n",
    "        print(zdr_ungridded.shape)\n",
    "        #Get ungridded gate altitudes\n",
    "        gate_altitude = radar.gate_altitude['data'][:]\n",
    "        #Convert to height ARL\n",
    "        h_agl = gate_altitude-radar.altitude['data'][0]\n",
    "        #Convert to height relative to calibration level\n",
    "        h_aoc = h_agl - h_oc\n",
    "\n",
    "        #Now start masking out ZDR data\n",
    "        zdr_c = np.copy(zdr_ungridded)\n",
    "        zdr_c = ma.masked_where(ref_ungridded < 20, zdr_c)\n",
    "        zdr_c = ma.masked_where(ref_ungridded > 35, zdr_c)\n",
    "        zdr_c = ma.masked_where(cc_ungridded < 0.99, zdr_c)\n",
    "        zdr_c = ma.masked_where(h_agl > (h_oc + 250), zdr_c)\n",
    "        zdr_c = ma.masked_where(h_agl < (h_oc - 250), zdr_c)\n",
    "        print(ma.MaskedArray.count(zdr_c))\n",
    "        #Testing for elevation stuff\n",
    "        alt_c = np.copy(h_agl)\n",
    "        alt_c = ma.masked_where(ref_ungridded < 20, alt_c)\n",
    "        alt_c = ma.masked_where(ref_ungridded > 35, alt_c)\n",
    "        alt_c = ma.masked_where(cc_ungridded < 0.99, alt_c)\n",
    "        alt_c = ma.masked_where(h_agl > (h_oc + 250), alt_c)\n",
    "        alt_c = ma.masked_where(h_agl < (h_oc - 250), alt_c)\n",
    "\n",
    "        #Get ungridded lats and lons\n",
    "        ungrid_lons = radar.gate_longitude['data']\n",
    "        ungrid_lats = radar.gate_latitude['data']\n",
    "        cenlat = radar.latitude['data'][0]\n",
    "        cenlon = radar.longitude['data'][0]\n",
    "        \n",
    "        #Get calibrations and raw means\n",
    "        zdr_m = np.nanmean(zdr_c)\n",
    "        zdr_ca = zdr_m - 0.2\n",
    "        zdr_cals.append(zdr_ca)\n",
    "        zdr_raw.append(zdr_m)\n",
    "            \n",
    "    return zdr_cals, zdr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-29 02:50:30.019995\n",
      "Downloaded KLBB20190524_010714_V06\n",
      "Downloaded KLBB20190524_011349_V06\n",
      "2 out of 2 files downloaded...0 errors\n",
      "2019-05-24 01:07:14.900000\n",
      "2019-12-29 02:50:55.160569\n",
      "(12600, 1832)\n",
      "7583\n",
      "2019-05-24 01:13:49.628000\n",
      "2019-12-29 02:51:23.222544\n",
      "(12600, 1832)\n",
      "8283\n",
      "Downloaded KRLX20190523_234414_V06\n",
      "Downloaded KRLX20190523_233812_V06\n",
      "2 out of 2 files downloaded...0 errors\n",
      "2019-05-23 23:38:12.766000\n",
      "2019-12-29 02:51:58.082778\n",
      "(11160, 1832)\n",
      "1837\n",
      "2019-05-23 23:44:14.071000\n",
      "2019-12-29 02:52:21.591870\n",
      "(11160, 1832)\n",
      "1375\n",
      "Downloaded KDDC20190612_001545_V06\n",
      "Downloaded KDDC20190612_001007_V06\n",
      "Downloaded KDDC20190612_000413_V06\n",
      "3 out of 3 files downloaded...0 errors\n",
      "2019-06-12 00:04:13.032000\n",
      "2019-12-29 02:53:02.077215\n",
      "(11160, 1832)\n",
      "3946\n",
      "2019-06-12 00:10:07.629000\n",
      "2019-12-29 02:53:25.559463\n",
      "(11160, 1832)\n",
      "3992\n",
      "2019-06-12 00:15:45.783000\n",
      "2019-12-29 02:53:49.278049\n",
      "(11160, 1832)\n",
      "4262\n",
      "Downloaded KSJT20190617_005744_V06_MDM\n",
      "Downloaded KSJT20190617_005744_V06\n",
      "Downloaded KSJT20190617_005222_V06\n",
      "3 out of 3 files downloaded...0 errors\n",
      "2019-06-17 00:52:22.959000\n",
      "2019-12-29 02:54:19.639387\n",
      "(9720, 1832)\n",
      "2772\n",
      "2019-06-17 00:57:44.519000\n",
      "2019-12-29 02:54:33.417278\n",
      "(9720, 1832)\n",
      "2563\n",
      "Downloaded KAMA20190619_010936_V06\n",
      "Downloaded KAMA20190619_011442_V06\n",
      "Downloaded KAMA20190619_010435_V06\n",
      "3 out of 3 files downloaded...0 errors\n",
      "2019-06-19 01:04:35.605000\n",
      "2019-12-29 02:55:11.292230\n",
      "(9720, 1832)\n",
      "15458\n",
      "2019-06-19 01:09:36.032000\n",
      "2019-12-29 02:55:32.131553\n",
      "(9720, 1832)\n",
      "16392\n",
      "2019-06-19 01:14:42.214000\n",
      "2019-12-29 02:55:53.557016\n",
      "(9720, 1832)\n",
      "18690\n",
      "Downloaded KLBB20190625_021209_V06\n",
      "Downloaded KLBB20190625_021620_V06\n",
      "Downloaded KLBB20190625_020346_V06\n",
      "Downloaded KLBB20190625_020758_V06\n",
      "4 out of 4 files downloaded...0 errors\n",
      "2019-06-25 02:03:46.185000\n",
      "2019-12-29 02:56:30.577184\n",
      "(8280, 1832)\n",
      "3886\n",
      "2019-06-25 02:07:58.059000\n",
      "2019-12-29 02:56:48.996932\n",
      "(8280, 1832)\n",
      "3940\n",
      "2019-06-25 02:12:09.172000\n",
      "2019-12-29 02:57:07.642079\n",
      "(8280, 1832)\n",
      "4214\n",
      "2019-06-25 02:16:20.128000\n",
      "2019-12-29 02:57:25.626992\n",
      "(8280, 1832)\n",
      "3954\n",
      "Downloaded KMPX20190726_235334_V06_MDM\n",
      "Downloaded KMPX20190727_000037_V06\n",
      "Downloaded KMPX20190726_235334_V06\n",
      "3 out of 3 files downloaded...0 errors\n",
      "2019-07-26 23:53:34.288000\n",
      "2019-12-29 02:57:58.201290\n",
      "(12600, 1832)\n",
      "1944\n",
      "2019-07-27 00:00:37.010000\n",
      "2019-12-29 02:58:25.848001\n",
      "(12600, 1832)\n",
      "1397\n",
      "Downloaded KUDX20190810_224007_V06\n",
      "Downloaded KUDX20190810_224450_V06\n",
      "Downloaded KUDX20190810_223523_V06\n",
      "3 out of 3 files downloaded...0 errors\n",
      "2019-08-10 22:35:23.043000\n",
      "2019-12-29 02:59:06.147911\n",
      "(9720, 1832)\n",
      "11223\n",
      "2019-08-10 22:40:07.209000\n",
      "2019-12-29 02:59:27.024101\n",
      "(9720, 1832)\n",
      "12135\n",
      "2019-08-10 22:44:50.166000\n",
      "2019-12-29 02:59:48.343075\n",
      "(9720, 1832)\n",
      "11977\n",
      "2019-12-29 03:00:01.556039\n"
     ]
    }
   ],
   "source": [
    "#Loop to run the actual algorithm\n",
    "print(datetime.utcnow())\n",
    "with open('Machine_Learning/ZDRCalsAMS8.csv', mode='w') as cal_file:\n",
    "    calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "#You can either run all example cases (commented out line) or one at a time (runing line)\n",
    "for i in range(len(durationstm)):\n",
    "#for i in [0]:\n",
    "    #zdr_cals, zdr_raw = multi_case_algorithm_ML1_loc(yearstm[i], monthstm[i], daystm[i], hourstm[i], start_minstm[i], durationstm[i], stationstm[i], h_calstm[i], localfolder[i])\n",
    "    zdr_cals, zdr_raw = multi_case_algorithm_ML1(yearstm[i], monthstm[i], daystm[i], hourstm[i], start_minstm[i], durationstm[i], stationstm[i], h_calstm[i])\n",
    "    with open('Machine_Learning/ZDRCalsAMS8.csv', mode='a') as cal_file:\n",
    "                calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "                calWriter.writerow([yearstm[i], monthstm[i], daystm[i], hourstm[i], start_minstm[i], np.nanmean(zdr_cals)])\n",
    "print(datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
